#!/bin/bash

# =============================================================================
# ADAPTIVE HIGH AVAILABILITY DEMONSTRATION
# =============================================================================
# Purpose: Demonstrate HA capabilities of the currently running Citus architecture
# Features: Detects environment and shows limitations/capabilities dynamically
# Author: Professional Staff Software Engineer Implementation
# =============================================================================

set -euo pipefail

# =============================================================================
# CONFIGURATION & CONSTANTS
# =============================================================================

# Color definitions
readonly RED='\033[0;31m'
readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BLUE='\033[0;34m'
readonly PURPLE='\033[0;35m'
readonly CYAN='\033[0;36m'
readonly ORANGE='\033[0;33m'
readonly BOLD='\033[1m'
readonly NC='\033[0m'

# Environment configurations
readonly STANDARD_COORDINATOR="citus_coordinator"
readonly STANDARD_WORKER1="citus_worker1"
readonly STANDARD_WORKER2="citus_worker2"
readonly STANDARD_DB="citus_platform"

readonly PATRONI_COORDINATOR1="citus_coordinator1"
readonly PATRONI_COORDINATOR2="citus_coordinator2"
readonly PATRONI_COORDINATOR3="citus_coordinator3"
readonly PATRONI_WORKER1_PRIMARY="citus_worker1_primary"
readonly PATRONI_WORKER1_STANDBY="citus_worker1_standby"
readonly PATRONI_WORKER2_PRIMARY="citus_worker2_primary"
readonly PATRONI_WORKER2_STANDBY="citus_worker2_standby"
readonly PATRONI_DB="citus_platform"

# Test parameters
readonly QUERY_TIMEOUT=10
readonly RECOVERY_WAIT=5
readonly FAILOVER_WAIT=3

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

log() {
    local level="$1"
    local message="$2"
    local timestamp
    timestamp=$(date '+%H:%M:%S')
    
    case "$level" in
        "INFO")  echo -e "${CYAN}[${timestamp}]${NC} ${message}" ;;
        "WARN")  echo -e "${YELLOW}[${timestamp}] âš ï¸${NC}  ${message}" ;;
        "ERROR") echo -e "${RED}[${timestamp}] âŒ${NC} ${message}" ;;
        "SUCCESS") echo -e "${GREEN}[${timestamp}] âœ…${NC} ${message}" ;;
    esac
}

print_header() {
    local title="$1"
    echo
    echo -e "${PURPLE}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${PURPLE}â•‘$(printf "%62s" | tr ' ' ' ')â•‘${NC}"
    echo -e "${PURPLE}â•‘$(printf "%*s" $((31 + ${#title}/2)) "$title")$(printf "%*s" $((31 - ${#title}/2)) "")â•‘${NC}"
    echo -e "${PURPLE}â•‘$(printf "%62s" | tr ' ' ' ')â•‘${NC}"
    echo -e "${PURPLE}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo
}

print_section() {
    local title="$1"
    echo
    echo -e "${BLUE}ðŸŽ¯ ${title}${NC}"
    echo -e "${BLUE}$(printf '=%.0s' $(seq 1 $((${#title} + 3))))${NC}"
}

container_exists() {
    local container="$1"
    docker ps -a --format '{{.Names}}' | grep -q "^${container}$" 2>/dev/null
}

container_running() {
    local container="$1"
    if ! container_exists "$container"; then
        return 1
    fi
    docker ps --format '{{.Names}}' | grep -q "^${container}$" 2>/dev/null
}

container_healthy() {
    local container="$1"
    if ! container_running "$container"; then
        return 1
    fi
    docker exec "$container" pg_isready -U postgres >/dev/null 2>&1
}

# =============================================================================
# ENVIRONMENT DETECTION
# =============================================================================

detect_current_architecture() {
    # Check Patroni Citus first (more sophisticated)
    if container_running "$PATRONI_COORDINATOR1"; then
        if container_healthy "$PATRONI_COORDINATOR1"; then
            echo "patroni"
            return 0
        fi
    fi
    
    # Check Standard Citus
    if container_running "$STANDARD_COORDINATOR"; then
        if container_healthy "$STANDARD_COORDINATOR"; then
            echo "standard"
            return 0
        fi
    fi
    
    echo "none"
}

get_patroni_leader() {
    # Check which coordinator is currently the Patroni leader
    if container_healthy "$PATRONI_COORDINATOR1" && docker exec "$PATRONI_COORDINATOR1" curl -s localhost:8008/ 2>/dev/null | grep -q '"role": "master"'; then
        echo "$PATRONI_COORDINATOR1"
    elif container_healthy "$PATRONI_COORDINATOR2" && docker exec "$PATRONI_COORDINATOR2" curl -s localhost:8008/ 2>/dev/null | grep -q '"role": "master"'; then
        echo "$PATRONI_COORDINATOR2"
    elif container_healthy "$PATRONI_COORDINATOR3" && docker exec "$PATRONI_COORDINATOR3" curl -s localhost:8008/ 2>/dev/null | grep -q '"role": "master"'; then
        echo "$PATRONI_COORDINATOR3"
    else
        echo "$PATRONI_COORDINATOR1"  # fallback
    fi
}

get_current_coordinator() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            echo "$STANDARD_COORDINATOR"
            ;;
        "patroni")
            get_patroni_leader
            ;;
        *)
            echo ""
            ;;
    esac
}

get_current_database() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            echo "$STANDARD_DB"
            ;;
        "patroni")
            echo "$PATRONI_DB"
            ;;
        *)
            echo ""
            ;;
    esac
}

# =============================================================================
# PATRONI LEADER DETECTION
# =============================================================================

# Helper function to detect current leader
detect_current_leader() {
    local coordinator_containers=(
        "citus_coordinator1" 
        "citus_coordinator2" 
        "citus_coordinator3"
    )
    
    for container in "${coordinator_containers[@]}"; do
        if docker exec "$container" curl -s http://localhost:8008/ 2>/dev/null | grep -q '"role": "master"'; then
            echo "$container"
            return 0
        fi
    done
    echo ""
}

# Wait for new leader election after failover
wait_for_leader_election() {
    local max_wait=60  # Maximum wait time in seconds
    local wait_time=0
    local check_interval=2
    
    echo "â³ Waiting for Patroni leader election..."
    
    while [ $wait_time -lt $max_wait ]; do
        local new_leader=$(detect_current_leader)
        if [ -n "$new_leader" ]; then
            echo "ðŸŽ¯ New leader elected: ${new_leader}"
            sleep 3  # Give new leader time to fully initialize
            return 0
        fi
        
        echo "   âš¡ Election in progress... (${wait_time}s elapsed)"
        sleep $check_interval
        wait_time=$((wait_time + check_interval))
    done
    
    echo "âš ï¸  Leader election taking longer than expected (${max_wait}s)"
    return 1
}

get_patroni_primary_worker() {
    local group="$1"  # 1 or 2
    local primary=""
    
    case "$group" in
        "1")
            if container_healthy "$PATRONI_WORKER1_PRIMARY"; then
                local recovery_status
                recovery_status=$(docker exec "$PATRONI_WORKER1_PRIMARY" psql -U postgres -t -c "SELECT pg_is_in_recovery();" 2>/dev/null | tr -d ' \n' || echo "t")
                if [[ "$recovery_status" == "f" ]]; then
                    primary="$PATRONI_WORKER1_PRIMARY"
                fi
            fi
            if [[ -z "$primary" ]] && container_healthy "$PATRONI_WORKER1_STANDBY"; then
                local recovery_status
                recovery_status=$(docker exec "$PATRONI_WORKER1_STANDBY" psql -U postgres -t -c "SELECT pg_is_in_recovery();" 2>/dev/null | tr -d ' \n' || echo "t")
                if [[ "$recovery_status" == "f" ]]; then
                    primary="$PATRONI_WORKER1_STANDBY"
                fi
            fi
            ;;
        "2")
            if container_healthy "$PATRONI_WORKER2_PRIMARY"; then
                local recovery_status
                recovery_status=$(docker exec "$PATRONI_WORKER2_PRIMARY" psql -U postgres -t -c "SELECT pg_is_in_recovery();" 2>/dev/null | tr -d ' \n' || echo "t")
                if [[ "$recovery_status" == "f" ]]; then
                    primary="$PATRONI_WORKER2_PRIMARY"
                fi
            fi
            if [[ -z "$primary" ]] && container_healthy "$PATRONI_WORKER2_STANDBY"; then
                local recovery_status
                recovery_status=$(docker exec "$PATRONI_WORKER2_STANDBY" psql -U postgres -t -c "SELECT pg_is_in_recovery();" 2>/dev/null | tr -d ' \n' || echo "t")
                if [[ "$recovery_status" == "f" ]]; then
                    primary="$PATRONI_WORKER2_STANDBY"
                fi
            fi
            ;;
    esac
    
    echo "$primary"
}

# =============================================================================
# TOPOLOGY DISPLAY
# =============================================================================

show_standard_topology() {
    print_section "STANDARD CITUS TOPOLOGY"
    
    echo -e "${BOLD}ðŸ“Š COORDINATOR:${NC}"
    if container_healthy "$STANDARD_COORDINATOR"; then
        echo -e "${GREEN}   âœ… $STANDARD_COORDINATOR (ACTIVE)${NC}"
    else
        echo -e "${RED}   âŒ $STANDARD_COORDINATOR (DOWN)${NC}"
    fi
    
    echo -e "${BOLD}ðŸ”„ WORKERS:${NC}"
    if container_healthy "$STANDARD_COORDINATOR"; then
        docker exec "$STANDARD_COORDINATOR" psql -U postgres -d "$STANDARD_DB" -c "
        SELECT 
            nodename as worker,
            nodeport as port,
            CASE WHEN isactive THEN 'âœ… ACTIVE' ELSE 'âŒ INACTIVE' END as status
        FROM pg_dist_node 
        WHERE noderole = 'primary'
        ORDER BY nodename;" 2>/dev/null || echo "   âš ï¸  Unable to query worker status"
    else
        echo -e "${RED}   âŒ Cannot query workers - coordinator down${NC}"
    fi
}

show_patroni_topology() {
    print_section "PATRONI CITUS TOPOLOGY"
    
    echo -e "${BOLD}ðŸ“Š COORDINATORS:${NC}"
    local leader
    leader=$(get_patroni_leader)
    
    for coord in "$PATRONI_COORDINATOR1" "$PATRONI_COORDINATOR2" "$PATRONI_COORDINATOR3"; do
        if container_healthy "$coord"; then
            if [[ "$coord" == "$leader" ]]; then
                echo -e "${GREEN}   âœ… $coord (LEADER)${NC}"
            else
                echo -e "${YELLOW}   ðŸŸ¡ $coord (REPLICA)${NC}"
            fi
        else
            echo -e "${RED}   âŒ $coord (DOWN)${NC}"
        fi
    done
    
    echo -e "${BOLD}ðŸ”„ WORKER GROUPS:${NC}"
    
    # Worker Group 1
    echo -e "${CYAN}   Group 1:${NC}"
    local w1_primary
    w1_primary=$(get_patroni_primary_worker "1")
    
    for worker in "$PATRONI_WORKER1_PRIMARY" "$PATRONI_WORKER1_STANDBY"; do
        if container_healthy "$worker"; then
            if [[ "$worker" == "$w1_primary" ]]; then
                echo -e "${GREEN}     âœ… $worker (PRIMARY)${NC}"
            else
                echo -e "${YELLOW}     ðŸŸ¡ $worker (STANDBY)${NC}"
            fi
        else
            echo -e "${RED}     âŒ $worker (DOWN)${NC}"
        fi
    done
    
    # Worker Group 2  
    echo -e "${CYAN}   Group 2:${NC}"
    local w2_primary
    w2_primary=$(get_patroni_primary_worker "2")
    
    for worker in "$PATRONI_WORKER2_PRIMARY" "$PATRONI_WORKER2_STANDBY"; do
        if container_healthy "$worker"; then
            if [[ "$worker" == "$w2_primary" ]]; then
                echo -e "${GREEN}     âœ… $worker (PRIMARY)${NC}"
            else
                echo -e "${YELLOW}     ðŸŸ¡ $worker (STANDBY)${NC}"
            fi
        else
            echo -e "${RED}     âŒ $worker (DOWN)${NC}"
        fi
    done
    
    # Show registered workers in Citus
    if [[ -n "$leader" ]]; then
        echo -e "${BOLD}ðŸ—‚ï¸  REGISTERED WORKERS:${NC}"
        docker exec "$leader" psql -U postgres -d "$PATRONI_DB" -c "
        SELECT 
            nodename as worker,
            nodeport as port,
            CASE WHEN isactive THEN 'âœ… ACTIVE' ELSE 'âŒ INACTIVE' END as status
        FROM pg_dist_node 
        WHERE noderole = 'primary'
        ORDER BY nodename;" 2>/dev/null || echo "   âš ï¸  Unable to query worker status"
    fi
}

# =============================================================================
# QUERY TESTING
# =============================================================================

test_query() {
    local env="$1"
    local coordinator="$2" 
    local database="$3"
    local description="$4"
    
    echo -e "${YELLOW}ðŸ” Testing: ${description}${NC}"
    
    local start_time
    start_time=$(date +%s.%N)
    
    local query_result
    if timeout "$QUERY_TIMEOUT" docker exec "$coordinator" psql -U postgres -d "$database" -c "
    SELECT 
        COUNT(*) as total_companies,
        COUNT(CASE WHEN name LIKE 'Company %' THEN 1 END) as test_companies,
        now() as query_time
    FROM companies;" 2>/dev/null; then
        local end_time
        end_time=$(date +%s.%N)
        local duration
        duration=$(echo "$end_time - $start_time" | bc 2>/dev/null | cut -c1-5 || echo "N/A")
        log "SUCCESS" "Query completed successfully (${duration}s)"
        return 0
    else
        local end_time
        end_time=$(date +%s.%N)  
        local duration
        duration=$(echo "$end_time - $start_time" | bc 2>/dev/null | cut -c1-5 || echo "N/A")
        log "ERROR" "Query failed after ${duration}s"
        return 1
    fi
}

# =============================================================================
# FAILOVER SIMULATION
# =============================================================================

simulate_coordinator_failure() {
    local env="$1"
    local coordinator="$2"
    
    # If no specific coordinator given, detect current leader for patroni
    if [[ -z "$coordinator" && "$env" == "patroni" ]]; then
        coordinator=$(get_patroni_leader)
        if [[ -z "$coordinator" ]]; then
            log "ERROR" "âŒ Could not detect current leader"
            return 1
        fi
    fi
    
    log "WARN" "ðŸ”¥ Pausing current leader: $coordinator"
    docker pause "$coordinator" 2>/dev/null || true
    
    if [[ "$env" == "patroni" ]]; then
        echo "âš¡ Patroni should elect new leader automatically..."
        echo "   This may take 5-15 seconds for leader election..."
        
        # Wait for new leader to be elected
        local attempts=0
        local max_attempts=15
        local new_leader=""
        
        while [[ $attempts -lt $max_attempts ]]; do
            sleep 2
            new_leader=$(get_patroni_leader)
            if [[ -n "$new_leader" && "$new_leader" != "$coordinator" ]]; then
                log "SUCCESS" "âœ… New leader elected: $new_leader"
                break
            fi
            attempts=$((attempts + 1))
            echo "   â³ Waiting for leader election... (${attempts}/${max_attempts})"
        done
        
        if [[ $attempts -eq $max_attempts ]]; then
            log "WARN" "âš ï¸  Leader election taking longer than expected"
            echo "   This is normal during coordinator failover"
        fi
        
        # Test queries after failover
        echo "ðŸ” Testing queries after automatic failover..."
        test_queries_during_failure "$env" "coordinator"
    else
        sleep "$FAILOVER_WAIT"
        log "ERROR" "ðŸ’¥ Coordinator $coordinator is DOWN - No automatic recovery!"
    fi
}

simulate_worker_failure() {
    local worker="$1"
    
    log "WARN" "ðŸ”¥ SIMULATING WORKER FAILURE: $worker"  
    docker pause "$worker" 2>/dev/null || true
    sleep "$FAILOVER_WAIT"
    log "ERROR" "ðŸ’¥ Worker $worker is DOWN"
}

recover_container() {
    local container="$1"
    
    log "INFO" "ðŸ”§ RECOVERING: $container"
    docker unpause "$container" 2>/dev/null || true
    sleep "$RECOVERY_WAIT"
    
    if container_healthy "$container"; then
        log "SUCCESS" "âœ… Container $container recovered successfully"
    else
        log "WARN" "âš ï¸  Container $container started but may need more time"
    fi
}

# =============================================================================
# ADAPTIVE TEST SCENARIOS
# =============================================================================

run_ha_demonstration() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            demonstrate_standard_limitations
            ;;
        "patroni") 
            demonstrate_patroni_capabilities
            ;;
        *)
            log "ERROR" "Unknown architecture: $arch"
            return 1
            ;;
    esac
}

demonstrate_standard_limitations() {
    print_header "STANDARD CITUS - HA LIMITATIONS DEMO"
    
    echo -e "${YELLOW}ðŸŽ¯ OBJECTIVE: Show limitations of basic Citus setup${NC}"
    echo -e "${YELLOW}   This will demonstrate why HA solutions like Patroni are needed${NC}"
    echo
    
    if ! container_healthy "$STANDARD_COORDINATOR"; then
        log "ERROR" "Standard Citus coordinator is not healthy. Please start the cluster first."
        return 1
    fi
    
    print_section "BASELINE TEST"
    show_standard_topology
    test_query "standard" "$STANDARD_COORDINATOR" "$STANDARD_DB" "Baseline query (healthy cluster)"
    
    echo -e "${CYAN}Press Enter to simulate coordinator failure...${NC}"
    read -r
    
    print_section "COORDINATOR FAILURE TEST"
    simulate_coordinator_failure "standard" "$STANDARD_COORDINATOR"
    show_standard_topology
    test_query "standard" "$STANDARD_COORDINATOR" "$STANDARD_DB" "Query during coordinator failure"
    
    echo -e "${CYAN}Press Enter to recover coordinator...${NC}"
    read -r
    
    print_section "COORDINATOR RECOVERY"
    recover_container "$STANDARD_COORDINATOR"
    
    # Wait for coordinator to be ready
    log "INFO" "â³ Waiting for coordinator to be ready..."
    local attempts=0
    while ! container_healthy "$STANDARD_COORDINATOR" && [[ $attempts -lt 30 ]]; do
        sleep 2
        ((attempts++))
    done
    
    show_standard_topology
    test_query "standard" "$STANDARD_COORDINATOR" "$STANDARD_DB" "Query after coordinator recovery"
    
    print_section "WORKER FAILURE TEST"
    echo -e "${CYAN}Press Enter to test worker failure...${NC}"
    read -r
    
    simulate_worker_failure "$STANDARD_WORKER1"
    show_standard_topology
    test_query "standard" "$STANDARD_COORDINATOR" "$STANDARD_DB" "Query with worker1 down"
    
    print_section "WORKER RECOVERY"
    echo -e "${CYAN}Press Enter to recover worker...${NC}"
    read -r
    
    recover_container "$STANDARD_WORKER1"
    show_standard_topology
    test_query "standard" "$STANDARD_COORDINATOR" "$STANDARD_DB" "Query after worker recovery"
    
    print_section "STANDARD CITUS - LIMITATIONS SUMMARY"
    echo -e "${RED}ï¿½ CRITICAL LIMITATIONS IDENTIFIED:${NC}"
    echo
    echo -e "   ${RED}âŒ SINGLE POINT OF FAILURE${NC}"
    echo -e "      â€¢ Coordinator failure = Complete cluster down"
    echo -e "      â€¢ No automatic failover mechanism"
    echo
    echo -e "   ${RED}âŒ DATA LOSS RISK${NC}"
    echo -e "      â€¢ No replication for coordinator"
    echo -e "      â€¢ Worker failures lose shard data"
    echo
    echo -e "   ${RED}âŒ MANUAL RECOVERY REQUIRED${NC}"
    echo -e "      â€¢ DBA intervention needed for all failures"
    echo -e "      â€¢ Long recovery times (minutes to hours)"
    echo
    echo -e "   ${RED}âŒ NOT PRODUCTION READY${NC}"
    echo -e "      â€¢ No 24/7 availability guarantees"
    echo -e "      â€¢ Unsuitable for mission-critical applications"
    
    echo
    echo -e "${CYAN}ðŸ’¡ SOLUTION: Use Patroni + Citus for production workloads${NC}"
    echo -e "${CYAN}   â€¢ Automatic failover in seconds${NC}"
    echo -e "${CYAN}   â€¢ Zero data loss with replication${NC}"
    echo -e "${CYAN}   â€¢ Self-healing cluster architecture${NC}"
}

demonstrate_patroni_capabilities() {
    print_header "PATRONI CITUS - HA CAPABILITIES DEMO"
    
    echo -e "${GREEN}ðŸŽ¯ OBJECTIVE: Show advanced HA capabilities of Patroni + Citus${NC}"
    echo -e "${GREEN}   This demonstrates production-ready high availability${NC}"
    echo
    
    local leader
    leader=$(get_patroni_leader)
    
    if [[ -z "$leader" ]]; then
        log "ERROR" "No Patroni leader found. Please start the Patroni cluster first."
        return 1
    fi
    
    print_section "BASELINE TEST"
    show_patroni_topology
    test_query "patroni" "$leader" "$PATRONI_DB" "Baseline query (healthy cluster)"
    
    echo -e "${CYAN}Press Enter to simulate leader failure...${NC}"
    read -r
    
    print_section "LEADER FAILURE TEST"
    simulate_coordinator_failure "patroni" "$leader"
    show_patroni_topology
    
    # Wait for new leader election
    log "INFO" "â³ Waiting for leader election..."
    sleep 10
    
    local new_leader
    new_leader=$(get_patroni_leader)
    
    if [[ -n "$new_leader" ]] && [[ "$new_leader" != "$leader" ]]; then
        log "SUCCESS" "ðŸŽ¯ NEW LEADER ELECTED: $new_leader"
        show_patroni_topology
        test_query "patroni" "$new_leader" "$PATRONI_DB" "Query with new leader"
    else
        log "WARN" "Leader election may still be in progress"
    fi
    
    echo -e "${CYAN}Press Enter to recover original leader...${NC}"
    read -r
    
    print_section "ORIGINAL LEADER RECOVERY"
    recover_container "$leader"
    sleep 10  # Allow time for Patroni to sync
    show_patroni_topology
    
    # Test with current leader (might have changed)
    local current_leader
    current_leader=$(get_patroni_leader)
    test_query "patroni" "$current_leader" "$PATRONI_DB" "Query after original leader recovery"
    
    print_section "WORKER FAILOVER TEST"
    echo -e "${CYAN}Press Enter to test worker failover...${NC}"
    read -r
    
    local w1_primary
    w1_primary=$(get_patroni_primary_worker "1")
    
    if [[ -n "$w1_primary" ]]; then
        simulate_worker_failure "$w1_primary"
        
        log "INFO" "â³ Waiting for worker failover..."
        sleep 10
        
        show_patroni_topology
        
        local new_w1_primary
        new_w1_primary=$(get_patroni_primary_worker "1")
        
        if [[ -n "$new_w1_primary" ]] && [[ "$new_w1_primary" != "$w1_primary" ]]; then
            log "SUCCESS" "ðŸŽ¯ WORKER FAILOVER SUCCESSFUL: $new_w1_primary is now primary"
        else
            log "WARN" "Worker failover may still be in progress"
        fi
        
        current_leader=$(get_patroni_leader)
        test_query "patroni" "$current_leader" "$PATRONI_DB" "Query after worker failover"
        
        echo -e "${CYAN}Press Enter to recover original worker...${NC}"
        read -r
        
        print_section "WORKER RECOVERY"
        recover_container "$w1_primary"
        sleep 10
        show_patroni_topology
        
        current_leader=$(get_patroni_leader)
        test_query "patroni" "$current_leader" "$PATRONI_DB" "Query after worker recovery"
    fi
    
    print_section "PATRONI CITUS - CAPABILITIES SUMMARY"
    echo -e "${GREEN}ï¿½ PRODUCTION-READY HA CAPABILITIES:${NC}"
    echo
    echo -e "   ${GREEN}âœ… AUTOMATIC FAILOVER${NC}"
    echo -e "      â€¢ Leader election in seconds"
    echo -e "      â€¢ No manual intervention required"
    echo
    echo -e "   ${GREEN}âœ… ZERO DATA LOSS${NC}"
    echo -e "      â€¢ Streaming replication"
    echo -e "      â€¢ Synchronous commit options"
    echo
    echo -e "   ${GREEN}âœ… SELF-HEALING ARCHITECTURE${NC}"
    echo -e "      â€¢ Automatic worker promotion"
    echo -e "      â€¢ Continuous availability"
    echo
    echo -e "   ${GREEN}âœ… PRODUCTION READY${NC}"
    echo -e "      â€¢ 99.9%+ availability possible"
    echo -e "      â€¢ Mission-critical application support"
    
    echo
    echo -e "${CYAN}ðŸŽ¯ RESULT: Enterprise-grade distributed database with HA${NC}"
}

# =============================================================================
# ARCHITECTURE ANALYSIS
# =============================================================================

show_architecture_analysis() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            show_standard_analysis
            ;;
        "patroni")
            show_patroni_analysis  
            ;;
        *)
            show_general_comparison
            ;;
    esac
}

show_standard_analysis() {
    print_header "STANDARD CITUS ANALYSIS"
    
    echo -e "${BOLD}ðŸ“Š CURRENT ARCHITECTURE ASSESSMENT${NC}"
    echo
    echo -e "${YELLOW}âš¡ STRENGTHS:${NC}"
    echo "   âœ… Simple setup and configuration"
    echo "   âœ… Low resource requirements"  
    echo "   âœ… Fast development iteration"
    echo "   âœ… Good for learning Citus concepts"
    
    echo
    echo -e "${RED}âš ï¸  CRITICAL LIMITATIONS:${NC}"
    echo "   âŒ Single point of failure (coordinator)"
    echo "   âŒ No automatic failover"
    echo "   âŒ Data loss risk during failures"
    echo "   âŒ Manual recovery required"
    echo "   âŒ Not suitable for production"
    
    echo
    echo -e "${CYAN}ðŸŽ¯ RECOMMENDATIONS:${NC}"
    echo "   â€¢ Use for: Development, testing, demos"
    echo "   â€¢ Avoid for: Production, mission-critical apps"
    echo "   â€¢ Upgrade to: Patroni + Citus for production"
}

show_patroni_analysis() {
    print_header "PATRONI CITUS ANALYSIS"
    
    echo -e "${BOLD}ðŸ“Š CURRENT ARCHITECTURE ASSESSMENT${NC}"
    echo
    echo -e "${GREEN}ï¿½ PRODUCTION STRENGTHS:${NC}"
    echo "   âœ… Automatic failover (seconds)"
    echo "   âœ… Zero data loss protection"
    echo "   âœ… Self-healing architecture" 
    echo "   âœ… Continuous availability"
    echo "   âœ… Enterprise-grade reliability"
    
    echo
    echo -e "${YELLOW}âš ï¸  CONSIDERATIONS:${NC}"
    echo "   â€¢ Higher complexity to setup"
    echo "   â€¢ More resource requirements"
    echo "   â€¢ Requires monitoring and ops knowledge"
    
    echo
    echo -e "${CYAN}ï¿½ PRODUCTION READY:${NC}"
    echo "   â€¢ Ideal for: Mission-critical applications"
    echo "   â€¢ Supports: 24/7 operations"
    echo "   â€¢ Enables: Enterprise SLA compliance"
}

show_general_comparison() {
    print_header "CITUS HA ARCHITECTURES"
    
    echo -e "${BOLD}ðŸ“Š ARCHITECTURE COMPARISON${NC}"
    echo
    printf "%-25s | %-15s | %-15s\n" "FEATURE" "STANDARD" "PATRONI"
    echo "$(printf '=%.0s' {1..60})"
    printf "%-25s | %-15s | %-15s\n" "Failover" "Manual" "Automatic"
    printf "%-25s | %-15s | %-15s\n" "Data Protection" "Limited" "Full"
    printf "%-25s | %-15s | %-15s\n" "Recovery Time" "Minutes" "Seconds"
    printf "%-25s | %-15s | %-15s\n" "Production Ready" "No" "Yes"
    printf "%-25s | %-15s | %-15s\n" "Setup Complexity" "Low" "High"
}

# =============================================================================
# HA DEMONSTRATION FUNCTIONS
# =============================================================================

run_ha_demonstration() {
    local arch="$1"
    
    print_header "HIGH AVAILABILITY DEMONSTRATION"
    
    case "$arch" in
        "standard")
            echo -e "${YELLOW}ðŸŽ¯ DEMONSTRATING: Standard Citus Limitations${NC}"
            echo -e "${YELLOW}   Purpose: Show where basic setup fails${NC}"
            echo
            demonstrate_standard_limitations
            ;;
        "patroni")
            echo -e "${GREEN}ðŸŽ¯ DEMONSTRATING: Patroni Citus Capabilities${NC}"
            echo -e "${GREEN}   Purpose: Show enterprise-grade resilience${NC}"
            echo
            demonstrate_patroni_capabilities
            ;;
        *)
            log "ERROR" "Invalid architecture: $arch"
            return 1
            ;;
    esac
}

demonstrate_standard_limitations() {
    print_section "STANDARD CITUS - LIVE FAILOVER TEST"
    
    echo -e "${YELLOW}ðŸŽ¯ LIVE DEMONSTRATION: Standard Citus under failure${NC}"
    echo -e "${YELLOW}   We'll run queries and simulate failures to show limitations${NC}"
    echo
    
    # Step 1: Baseline test
    echo -e "${CYAN}ðŸ“Š STEP 1: Baseline Performance${NC}"
    echo "Running baseline queries on healthy cluster..."
    run_baseline_queries "standard"
    
    echo -e "${CYAN}Press Enter to continue to failure simulation...${NC}"
    read -r
    
    # Step 2: Worker failure
    echo -e "${RED}ï¿½ STEP 2: Worker Failure Simulation${NC}"
    echo "Simulating worker failure while running queries..."
    simulate_worker_failure "standard"
    
    echo -e "${CYAN}Press Enter to continue to coordinator failure...${NC}"
    read -r
    
    # Step 3: Coordinator failure (devastating)
    echo -e "${RED}ðŸš¨ STEP 3: Coordinator Failure (Critical)${NC}"
    echo "Simulating coordinator failure - this will break everything..."
    simulate_coordinator_failure "standard"
    
    echo -e "${CYAN}Press Enter to recover and see results...${NC}"
    read -r
    
    # Recovery
    recover_all_services "standard"
    show_standard_limitations_summary
}

demonstrate_patroni_capabilities() {
    print_section "PATRONI CITUS - LIVE RESILIENCE TEST"
    
    echo -e "${GREEN}ðŸŽ¯ LIVE DEMONSTRATION: Patroni Citus under failure${NC}"
    echo -e "${GREEN}   Watch how queries continue working despite failures!${NC}"
    echo
    
    # Step 1: Baseline test
    echo -e "${CYAN}ðŸ“Š STEP 1: Baseline Performance${NC}"
    echo "Running baseline queries on healthy cluster..."
    run_baseline_queries "patroni"
    
    echo -e "${CYAN}Press Enter to start failure tests...${NC}"
    read -r
    
    # Step 2: Worker failure (should handle gracefully)
    echo -e "${YELLOW}ðŸ’¥ STEP 2: Worker Primary Failure${NC}"
    echo "Failing worker primary - watch automatic failover!"
    simulate_worker_failure "patroni"
    
    echo -e "${CYAN}Press Enter to test coordinator failover...${NC}"
    read -r
    
    # Step 3: Coordinator failover (should be automatic)
    echo -e "${ORANGE}ðŸ”„ STEP 3: Coordinator Failover${NC}"
    echo "Failing coordinator leader - Patroni should elect new leader!"
    simulate_coordinator_failure "patroni"
    
    echo -e "${CYAN}Press Enter to see final results...${NC}"
    read -r
    
    # Recovery and summary
    recover_all_services "patroni"
    show_patroni_capabilities_summary
}

test_cluster_connectivity() {
    local arch="$1"
    local coordinator
    
    coordinator=$(get_current_coordinator "$arch")
    
    if [[ -z "$coordinator" ]]; then
        return 1
    fi
    
    # Simple connectivity test
    if ! container_healthy "$coordinator"; then
        return 1
    fi
    
    # Test database connectivity
    local db_name
    case "$arch" in
        "standard") db_name="$STANDARD_DB" ;;
        "patroni") db_name="$PATRONI_DB" ;;
    esac
    
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -c "SELECT 1;" >/dev/null 2>&1; then
        return 0
    else
        return 1
    fi
}

# =============================================================================
# PRACTICAL TESTING FUNCTIONS
# =============================================================================

run_baseline_queries() {
    local arch="$1"
    local coordinator
    coordinator=$(get_current_coordinator "$arch")
    
    local db_name
    case "$arch" in
        "standard") db_name="$STANDARD_DB" ;;
        "patroni") db_name="$PATRONI_DB" ;;
    esac
    
    echo -e "${CYAN}ðŸ” Testing query performance...${NC}"
    
    # Test 1: Simple count query
    echo -n "   â€¢ Company count query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM companies;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… SUCCESS${NC}"
    else
        echo -e "${RED}âŒ FAILED${NC}"
    fi
    
    # Test 2: Distributed query
    echo -n "   â€¢ Distributed campaign query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM campaigns;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… SUCCESS${NC}"
    else
        echo -e "${RED}âŒ FAILED${NC}"
    fi
    
    # Test 3: Join query
    echo -n "   â€¢ Cross-table join query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM companies c JOIN campaigns camp ON c.id = camp.company_id;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… SUCCESS${NC}"
    else
        echo -e "${RED}âŒ FAILED${NC}"
    fi
    
    echo -e "${GREEN}ðŸ“Š Baseline: All queries working normally${NC}"
}

simulate_worker_failure() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            echo -e "${RED}ðŸ’¥ Pausing worker1...${NC}"
            docker pause "$STANDARD_WORKER1" 2>/dev/null || true
            sleep 2
            
            echo -e "${YELLOW}ðŸ” Testing queries with failed worker...${NC}"
            test_queries_during_failure "$arch"
            ;;
        "patroni")
            echo -e "${YELLOW}ðŸ’¥ Pausing worker1-primary...${NC}"
            docker pause "$PATRONI_WORKER1_PRIMARY" 2>/dev/null || true
            sleep 3
            
            echo -e "${CYAN}ðŸ”„ Patroni should promote standby automatically...${NC}"
            sleep 3
            
            echo -e "${GREEN}ðŸ” Testing queries after automatic failover...${NC}"
            test_queries_during_failure "$arch"
            ;;
    esac
}

simulate_coordinator_failure() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            echo -e "${RED}ðŸš¨ Pausing coordinator...${NC}"
            docker pause "$STANDARD_COORDINATOR" 2>/dev/null || true
            sleep 2
            
            echo -e "${RED}ðŸ’€ This will break everything - no coordinator redundancy!${NC}"
            test_queries_during_failure "$arch"
            ;;
        "patroni")
            local current_leader
            current_leader=$(get_patroni_leader)
            echo -e "${YELLOW}ðŸ”„ Pausing current leader: $current_leader${NC}"
            docker pause "$current_leader" 2>/dev/null || true
            
            echo -e "${GREEN}âš¡ Patroni should elect new leader automatically...${NC}"
            
            # Wait for new leader election
            if wait_for_leader_election; then
                echo -e "${CYAN}ðŸ” Testing queries with new coordinator setup...${NC}"
                test_queries_during_failure "$arch" "coordinator"
            else
                echo -e "${YELLOW}âš ï¸  Leader election incomplete - testing anyway...${NC}"
                test_queries_during_failure "$arch" "coordinator"
            fi
            ;;
    esac
}

test_queries_during_failure() {
    local arch="$1"
    local failure_type="${2:-worker}"  # worker or coordinator
    local coordinator
    
    # For coordinator failures in Patroni, we need to detect the new leader
    if [[ "$failure_type" == "coordinator" && "$arch" == "patroni" ]]; then
        coordinator=$(get_patroni_leader)
        if [[ -z "$coordinator" ]]; then
            echo -e "${YELLOW}ðŸ” Testing queries during leader transition...${NC}"
            echo -e "${YELLOW}   âš ï¸  No leader currently available - election may still be in progress${NC}"
            
            # Try a few more times with short waits
            local retries=3
            for i in $(seq 1 $retries); do
                echo -e "${YELLOW}   â³ Retry $i/$retries - checking for new leader...${NC}"
                sleep 2
                coordinator=$(get_patroni_leader)
                if [[ -n "$coordinator" ]]; then
                    echo -e "${GREEN}   ðŸŽ¯ New leader found: $coordinator${NC}"
                    break
                fi
            done
            
            if [[ -z "$coordinator" ]]; then
                echo -e "${ORANGE}   âš ï¸  Still no leader - testing will show connection failures${NC}"
                coordinator="citus_coordinator1"  # Use fallback for testing
            fi
        fi
    else
        coordinator=$(get_current_coordinator "$arch")
    fi
    
    local db_name
    case "$arch" in
        "standard") db_name="$STANDARD_DB" ;;
        "patroni") db_name="$PATRONI_DB" ;;
    esac
    
    echo -e "${CYAN}ðŸ” Query results during failure:${NC}"
    
    # Test 1: Reference table (should always work)
    echo -n "   â€¢ Basic company query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM companies;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… STILL WORKS${NC}"
    else
        echo -e "${RED}âŒ FAILED${NC}"
    fi
    
    # Test 2: Distributed query (may fail during worker failure)
    echo -n "   â€¢ Distributed campaign query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM campaigns;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… STILL WORKS${NC}"
    else
        case "$arch" in
            "standard")
                echo -e "${RED}âŒ FAILED - DATA UNAVAILABLE${NC}"
                ;;
            "patroni")
                echo -e "${YELLOW}â³ TEMPORARY FAILURE - Patroni failover in progress${NC}"
                # Wait a bit and retry
                sleep 3
                echo -n "   â€¢ Retrying after Patroni failover: "
                if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM campaigns;" >/dev/null 2>&1; then
                    echo -e "${GREEN}âœ… RECOVERED AUTOMATICALLY${NC}"
                else
                    echo -e "${YELLOW}â³ Still failing - may need more time${NC}"
                fi
                ;;
        esac
    fi
    
    # Test 3: Join query (should work if both tables are accessible)
    echo -n "   â€¢ Cross-table join query: "
    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM companies c JOIN campaigns camp ON c.id = camp.company_id;" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… STILL WORKS${NC}"
    else
        case "$arch" in
            "standard")
                echo -e "${RED}âŒ FAILED - CROSS-SHARD DATA UNAVAILABLE${NC}"
                ;;
            "patroni")
                echo -e "${YELLOW}â³ TEMPORARY FAILURE - Waiting for failover${NC}"
                # Wait a bit and retry for coordinator failovers
                if [[ "$failure_type" == "coordinator" ]]; then
                    sleep 3
                    echo -n "   â€¢ Retrying cross-table join: "
                    if docker exec "$coordinator" psql -U postgres -d "$db_name" -t -c "SELECT COUNT(*) FROM companies c JOIN campaigns camp ON c.id = camp.company_id;" >/dev/null 2>&1; then
                        echo -e "${GREEN}âœ… RECOVERED AUTOMATICALLY${NC}"
                    else
                        echo -e "${YELLOW}â³ Still recovering - coordinator stabilizing${NC}"
                    fi
                fi
                ;;
        esac
    fi
}

recover_all_services() {
    local arch="$1"
    
    echo -e "${CYAN}ðŸ”§ Recovering all services...${NC}"
    
    case "$arch" in
        "standard")
            docker unpause "$STANDARD_COORDINATOR" 2>/dev/null || true
            docker unpause "$STANDARD_WORKER1" 2>/dev/null || true
            docker unpause "$STANDARD_WORKER2" 2>/dev/null || true
            ;;
        "patroni")
            docker unpause "$PATRONI_COORDINATOR1" 2>/dev/null || true
            docker unpause "$PATRONI_COORDINATOR2" 2>/dev/null || true
            docker unpause "$PATRONI_COORDINATOR3" 2>/dev/null || true
            docker unpause "$PATRONI_WORKER1_PRIMARY" 2>/dev/null || true
            docker unpause "$PATRONI_WORKER1_STANDBY" 2>/dev/null || true
            docker unpause "$PATRONI_WORKER2_PRIMARY" 2>/dev/null || true
            docker unpause "$PATRONI_WORKER2_STANDBY" 2>/dev/null || true
            ;;
    esac
    
    sleep 5
    echo -e "${GREEN}âœ… Recovery complete${NC}"
}

show_standard_limitations_summary() {
    print_section "STANDARD CITUS - LIMITATIONS REVEALED"
    
    echo -e "${RED}ðŸ“‹ CRITICAL ISSUES DEMONSTRATED:${NC}"
    echo -e "${RED}   âŒ Single coordinator = total failure point${NC}"
    echo -e "${RED}   âŒ Worker failures cause data unavailability${NC}"
    echo -e "${RED}   âŒ No automatic recovery mechanisms${NC}"
    echo -e "${RED}   âŒ Manual intervention required for all failures${NC}"
    echo
    echo -e "${YELLOW}âš ï¸  PRODUCTION IMPACT:${NC}"
    echo "   â€¢ Extended downtime during failures"
    echo "   â€¢ Data loss risk"  
    echo "   â€¢ Requires 24/7 manual monitoring"
    echo "   â€¢ Not suitable for mission-critical applications"
}

show_patroni_capabilities_summary() {
    print_section "PATRONI CITUS - ENTERPRISE RESILIENCE PROVEN"
    
    echo -e "${GREEN}ðŸ“‹ CAPABILITIES DEMONSTRATED:${NC}"
    echo -e "${GREEN}   âœ… Automatic coordinator failover${NC}"
    echo -e "${GREEN}   âœ… Worker redundancy with streaming replication${NC}"
    echo -e "${GREEN}   âœ… Queries continue during failures${NC}"
    echo -e "${GREEN}   âœ… Zero data loss during planned failovers${NC}"
    echo
    echo -e "${CYAN}ðŸš€ PRODUCTION ADVANTAGES:${NC}"
    echo "   â€¢ Sub-minute recovery times"
    echo "   â€¢ Automatic failure detection and recovery"
    echo "   â€¢ Suitable for 24/7 mission-critical operations"
    echo "   â€¢ Enterprise SLA compliance ready"
}

show_architecture_analysis() {
    local arch="$1"
    
    case "$arch" in
        "standard")
            show_standard_analysis
            ;;
        "patroni")
            show_patroni_analysis
            ;;
    esac
}

# =============================================================================
# ADAPTIVE MAIN MENU
# =============================================================================

show_menu() {
    local arch
    arch=$(detect_current_architecture)
    
    print_header "ADAPTIVE HA DEMONSTRATION"
    
    case "$arch" in
        "standard")
            echo -e "${YELLOW}ðŸŽ¯ DETECTED: Standard Citus Cluster${NC}"
            echo -e "${YELLOW}   Mode: Limitation Demonstration${NC}"
            echo
            echo -e "${BOLD}Available Options:${NC}"
            echo -e "${GREEN}1)${NC} Run HA Limitations Demo"
            echo -e "${CYAN}2)${NC} Show Architecture Analysis"  
            echo -e "${CYAN}3)${NC} Cluster Topology"
            echo -e "${RED}4)${NC} Exit"
            ;;
        "patroni")
            echo -e "${GREEN}ðŸŽ¯ DETECTED: Patroni Citus Cluster${NC}"
            echo -e "${GREEN}   Mode: Capabilities Demonstration${NC}"
            echo
            echo -e "${BOLD}Available Options:${NC}"
            echo -e "${GREEN}1)${NC} Run HA Capabilities Demo"
            echo -e "${CYAN}2)${NC} Show Architecture Analysis"
            echo -e "${CYAN}3)${NC} Cluster Topology"
            echo -e "${RED}4)${NC} Exit"
            ;;
        *)
            echo -e "${RED}âŒ NO ACTIVE CLUSTER DETECTED${NC}"
            echo
            echo -e "${YELLOW}Please start a Citus cluster first:${NC}"
            echo -e "${YELLOW}   Standard: docker-compose up -d${NC}"
            echo -e "${YELLOW}   Patroni:   ./02_simple_setup.sh${NC}"
            echo
            echo -e "${RED}1)${NC} Exit"
            ;;
    esac
    
    echo
    read -p "Enter your choice: " choice
    
    case "$arch" in
        "standard"|"patroni")
            case "$choice" in
                1)
                    run_ha_demonstration "$arch"
                    ;;
                2)
                    show_architecture_analysis "$arch"
                    ;;
                3)
                    case "$arch" in
                        "standard") show_standard_topology ;;
                        "patroni") show_patroni_topology ;;
                    esac
                    ;;
                4)
                    log "INFO" "Goodbye!"
                    exit 0
                    ;;
                *)
                    log "ERROR" "Invalid choice."
                    ;;
            esac
            ;;
        *)
            case "$choice" in
                1)
                    log "INFO" "Goodbye!"
                    exit 0
                    ;;
                *)
                    log "ERROR" "Invalid choice."
                    ;;
            esac
            ;;
    esac
}

# =============================================================================
# MAIN EXECUTION
# =============================================================================

main() {
    # Dependency check
    if ! command -v docker >/dev/null 2>&1; then
        log "ERROR" "Docker is required but not installed"
        exit 1
    fi
    
    if ! command -v bc >/dev/null 2>&1; then
        log "WARN" "bc not found - timing measurements will be limited"
    fi
    
    # Main loop
    while true; do
        show_menu
        echo
        echo -e "${CYAN}Press Enter to return to menu...${NC}"
        read -r
    done
}

# Handle script interruption gracefully  
trap 'log "WARN" "Script interrupted by user"; exit 130' INT

# Execute main function
main "$@"